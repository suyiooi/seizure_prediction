---
title: "nestedCV_filters_4 models"
description: "nested CV, with perm/PCA/AUC/no filter, in parallel"
author: "Suyi Ooi"
date: "2024-09-30"
output: html_document
---
#libraries
```{r libraries, include=FALSE}
#data
library(data.table)
library(dplyr)
library(ggpubr)
library(ggplot2)
library(patchwork)
library(igraph)

#ml/mlr3
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(mlr3filters)
library(mlr3fselect)
library(FSelectorRcpp)
library(mlr3pipelines)
library(mlr3benchmark)
library(mlr3data)
library(paradox)
library(mlr3viz)
library(precrec)
library(mlr3measures)
library(e1071)
library(mlr3tuningspaces)
library(genalg)
library(xgboost)
library(factoextra)
library(FactoMineR)

#model intepretation
library(iml)
library(interp)
library(pROC)

#harmonisation
library(neuroCombat)

#parallelisation
library(future)
library(future.apply)

#functions and hyperparameters
setwd("~/Library/CloudStorage/OneDrive-TheUniversityofMelbourne/scripts/chap3")
source("functions.R")

```
#data
```{r data, include=FALSE}
#load t1 (clin and imaging), and brainPAD
t1 <- read.csv("~/Library/CloudStorage/OneDrive-TheUniversityofMelbourne/freesurfer/freesurfer_stats/t1w.clin.image.scan.201.csv", header = TRUE)
brainage <- read.csv("~/Library/CloudStorage/OneDrive-TheUniversityofMelbourne/freesurfer/freesurfer_stats/PyBrainAge_Output_suyi_20240709.csv", header = TRUE)

t1$X = NULL
t1$sex[t1$sex == "nonbinary"] <- "male"

brainage <- subset(brainage, select = c("BrainAge","BrainPAD"))

#combine imaging and brainage
t1.data = data.frame(t1,brainage)

#remove bendigo skyra and one subject
t1.dat = t1.data %>% filter(batch != "bendigo_skyra",
                            subject != "sub-eh0703")

#make categorical variables factor
t1.dat <- t1.dat %>% dplyr::mutate(across(where(is.character), factor))

#reference levels
t1.dat$szrec1 <- relevel(t1.dat$szrec1, ref = "no") #predicting YES
t1.dat$sz_type <- relevel(t1.dat$sz_type, ref = "unc") 
t1.dat$mri <- relevel(t1.dat$mri, ref = "normal") #predict abnormal
t1.dat$eeg <- relevel(t1.dat$eeg, ref = "normal")
t1.dat$risk_factors___3 <- relevel(t1.dat$risk_factors___3, ref = "no")

#preprocess - prefix subcortical features for grep
start_hat <- which(names(t1.dat) == "r_lat_nucleus")
end_hat <- which(names(t1.dat) == "l_hippo_whole")
hat_range <- start_hat:end_hat
colnames(t1.dat)[start_hat:end_hat] <- paste0("subcort_", colnames(t1.dat[start_hat:end_hat]))

```
#filters
```{r filters}

filter_methods <- list(
  "pca" = po("pca") %>>% po("filter", filter = flt("variance"), filter.frac = 0.8),
  "perm" = po("filter", filter = flt("permutation"), param_vals = list(filter.frac = 0.3)),
  "auc_filter" = po("filter", filter = flt("auc"), param_vals = list(filter.frac = 0.5)),
  "no_filter" = po("nop"))

#factor preprocessing
factor_pipeline = po("removeconstants") %>>%
  po("collapsefactors", no_collapse_above_prevalence = 0.01) %>>%
  po("encode", method = "one-hot",
     affect_columns = selector_cardinality_greater_than(2),
     id = "low_card_enc") %>>%
  po("encode", method = "treatment",
     affect_columns = selector_type("factor"), id = "binary_enc") %>>% po("scale","center") 


```
#task
```{r learner}
#define the task
task = TaskClassif$new(t1.dat, id = "szrec", target = "szrec1")

#learners
learners <- list(lrn("classif.ranger",
                     id = "classif.ranger",
                     importance = "permutation",
                     predict_type = "prob"),
                 lrn("classif.xgboost",
                     id = "classif.xgboost",
                     predict_type = "prob"),
                 lrn("classif.glmnet",
                     id = "classif.glmnet",
                     predict_type = "prob"),
                 lrn("classif.svm",
                     id = "classif.svm",
                     type = "C-classification", kernel = "linear",
                     predict_type = "prob"))

# define measure
measure = msr("classif.auc")

#tuning grid
tuner = mlr3tuning::tnr("random_search", batch_size = 1)

#store results

train_sets <- list()
test_sets <- list()

results <- list()
inner_performance <- list()
outer_performance <- list()
outer_predictions <- list()
final_models <- list()
best_model_params <- list()

clin_rr_train <- list()
clin_auc <- list()
clin_pred <- list()
clin_model <- list()

#rsmp strategy
outer_rsmp <- rsmp("custom")
inner_rsmp = rsmp("cv", folds = 10)
```
#nested CV
```{r outer, include=FALSE, r echo=FALSE, results='hide'}

#folds
set.seed(4)
k <- 10 
folds <- stratified_folds(task, k)

# outer fold

for (i in seq_len(k)) {
  
  test_set <- folds[[i]]
  train_set <- setdiff(task$row_ids, test_set)
  outer_rsmp$instantiate(task, list(train_set), list(test_set))
  
  train_sets[[i]] <- train_set #store these to check the shuffled indices
  test_sets[[i]] <- test_set
  
  #apply combat on the training set
  train_data <- t1.dat[train_set, ]
  test_data <- t1.dat[test_set, ]
  
  #extract feature lists
  train_df_list <- extract_featuregroup_list(train_data)
  test_df_list  <- extract_featuregroup_list(test_data)
  
  #covariates for combat
  covars.train = model.matrix(~age+factor(sex)+factor(szrec1), data=train_data)
  
  #batch
  batch.train = train_data$batch
  batch.test = test_data$batch 
  
  #apply combat function
  combat.train <- do_neuroCombat(train_df_list, batch.train, covars.train)
  
  #get dat.combat and estimates
  dat.combat.train.list <- lapply(combat.train, function(x) x$dat.combat)
  
  dat.combat.train <- get_dat_combated_df(dat.combat.train.list)
  
  #apply combat on test using the previously generated estimates
  cb.train.estimates <- lapply(combat.train, function(x) x$estimates)
  
  dat.combat.test.list <- do_neuroCombatFromTraining(
    test_df_list, batch.test, cb.train.estimates)
  
  dat.combat.test <- get_dat_combated_df(dat.combat.test.list)
  
  #extract clinical factor variables
  t1.clin <- extract_clin_factors(train_data)
  t1.clin.test <- extract_clin_factors(test_data)
  
  #combine combated df with clinical factors
  t1.train.new <- data.frame(t1.clin, dat.combat.train)
  t1.test.new <- data.frame(t1.clin.test, dat.combat.test)
  
  #outer train and test tasks
  outer_train_task = TaskClassif$new(t1.train.new, id = "train", target = "szrec1")
  outer_test_task = TaskClassif$new(t1.test.new, id = "test", target = "szrec1")
  
  #make inner train task from outer train set
  inner_train_task = outer_train_task$clone()
  
  
  graph_learners = list()
  
    for (learner in learners) {
    
    #make graph learners with the filters piped
      
        for (filter in names(filter_methods)) {
        
          graph_name <- paste(filter, learner$clone()$id, sep = ".")
        graph <- factor_pipeline %>>% filter_methods[[filter]] %>>%
          learner$clone()
        graph_learner <- GraphLearner$new(graph)
        graph_learner$id <- graph_name
        graph_learners <- c(graph_learners,
                          list(GraphLearner$new(graph_learner)))
        }
    } #end learners 

  #inner loop: hyperparameter tuning for each graph learner
  
  results[[i]] <- list()
  
  for (j in seq_along(graph_learners)){
    
    #run inner loop in parallel
    
    future::plan(multisession, workers = 4) #uses workers are specified
      
    glrn <- graph_learners[[j]]
    
    results[[i]][[j]] <- future_lapply(list(glrn), function(glrn){
  
    #fallback
    glrn$encapsulate <- c(train = "evaluate", predict = "evaluate")
    glrn$fallback = lrn("classif.log_reg", predict_type = "prob")
    
    #hyperparameter set
    param_set <- create_param_sets(glrn$id)
    
    #tuning instance
    instance <- TuningInstanceSingleCrit$new(
      task = inner_train_task,
      learner = glrn,
      resampling = inner_rsmp,
      measure = measure,
      search_space = param_set,
      terminator = trm("evals", n_evals = 5) #may increase
    )
    
    tuner$optimize(instance)
    
    #instance$result_learner_param_vals
    #autoplot(instance)
    
    #tuned learner
    glrn$param_set$values = instance$result_learner_param_vals
    
    #inner evaluation
    rr_inner <- resample(inner_train_task, glrn,
                         inner_rsmp,
                         store_models = FALSE)
    
    inner_auc <- rr_inner$aggregate(measure)
    
    # Perform outer loop train/test
    glrn$train(outer_train_task)
    outer_prediction <- glrn$predict(outer_test_task)
    outer_auc = outer_prediction$score(measure)
    
    #store results for each glrn
    list(
      learner = glrn$id,
      inner_performance = inner_auc,
      outer_performance = outer_auc,
      best_params = instance$result_learner_param_vals,
      outer_prediction = outer_prediction,
      model = glrn
    )
  }, future.seed = TRUE)
  
}

    #clinical model
  
    #clin task train
    clin_task = outer_train_task$clone()
    clin_task$select(c("sex","age","mri",
                                 "nocturnal_sz",
                                 "risk_factors___2","risk_factors___3",
                                 "risk_factors___9","sz_type","eeg"))
    
    #clin task test
    clin_test_task = outer_test_task$clone()
    clin_test_task$select(c("sex","age","mri",
                                 "nocturnal_sz",
                                 "risk_factors___2","risk_factors___3",
                                 "risk_factors___9","sz_type","eeg"))

    #learner
    lrn_clin = lrn("classif.log_reg", predict_type = "prob")

    clin_glm = as_learner(factor_pipeline %>>% lrn_clin)

    instance_clin <- TuningInstanceSingleCrit$new(
      task = clin_task,
      learner = clin_glm,
      resampling = rsmp("cv", folds = 10),
      measure = measure,
      terminator = trm("evals", n_evals = 10) # change this
    )

    clin_rr <- resample(clin_task, clin_glm, rsmp("cv", folds = 10),
                        store_models = FALSE)
    clin_rr_train[[i]] <- clin_rr$aggregate(measure)

    #train on train
    clin_glm$train(clin_task)
    
    #predict on test
    pred_clin = clin_glm$predict(clin_test_task)
    
    #auc
    clin_performance = pred_clin$score(msr("classif.auc"))
  
  #stores clinical model results
    
  clin_auc[[i]] <- clin_performance
  clin_pred[[i]] <- list(pred_clin)
  clin_model[[i]] <- clin_glm
  
} # end outer

```
#extract results
```{extract results}

#outer_auc
outer_auc <- extract_auc(results, "outer")
inner_auc <- extract_auc(results, "inner")

#top 4 models + clinical
models <- list(
  "pca.classif.ranger" = "pred_stack_rf",
  "no_filter.classif.xgboost" = "pred_stack_xgb",
  "pca.classif.glmnet" = "pred_stack_glm",
  "no_filter.classif.svm" = "pred_stack_svm"
)

predictions <- stack_top4_predictions(results, models) 

```
#rocs
```{rocs}

colors <- c("darkblue", "darkred", "darkgreen", "darkorange", "dodgerblue")

labels <- c(
  paste0("1. Support Vector Machine (AUC = ", round(predictions$svm_stacked_roc$auc, digits = 2), ")"),
  paste0("2. Random Forest (AUC = ", round(predictions$rf_stacked_roc$auc, digits = 2), ")"),
  paste0("3. LASSO (AUC = ", round(predictions$glm_stacked_roc$auc, digits = 2), ")"),
  paste0("4. XGBoost (AUC = ", round(predictions$xgb_stacked_roc$auc, digits = 2), ")"),
  paste0("5. Clinical Model (AUC = ", round(predictions$clin_stacked_roc$auc, digits = 2), ")")
)

plot_rocs(predictions)

```
#model intepretation
```{r intepretation}
#roc.test
p<-roc.test(svm_stacked_roc, clin_stack_roc)
p

#PCA loadings
pca_glm_model3 = final_models[[3]][["pca.classif.glmnet"]]
pca_glm_filter = pca_glm_model3$graph_model$pipeops[[1]]$state$model

# PC1:124
glm_pca_loadings = as.data.frame(pca_glm_filter$pca$rotation[,1:126])

#shapley
outer_test_data = as.data.table(outer_test_task$clone()$data())

predictor_function = function(model, newdata) {
  newdata = as.data.table(newdata)
  prediction = model$predict_newdata(newdata)
  prediction$prob
}

# predictor object
auc_filter_svm_model3 <- final_models[[3]][["auc_filter.classif.svm"]]
no_filter_svm_model3 <- final_models[[3]][["no_filter.classif.svm"]]

svm_predictor = Predictor$new(
  model = auc_filter_svm_model3,
  data = outer_test_data[,-1, with = FALSE],  
  y = outer_test_data[,1],
  type = "prob",
  class = "yes"
)

svm_predictor2 = Predictor$new(
  model = no_filter_svm_model3,
  data = outer_test_data[,-1, with = FALSE],  
  y = outer_test_data[,1],
  type = "prob",
  class = "yes"
)

# 'average' shap for svm_predictor
shapley_list_svm = list()
for (i in 1:21) {
  shapley_svm = Shapley$new(svm_predictor, x.interest = as.data.frame(outer_test_data[i, ]), sample.size = 5)
  shapley_values_svm = as.data.frame(shapley_svm$results)
  shapley_values_svm$instance = i
  shapley_list_svm[[i]] = shapley_values_svm
}

shapley_all_svm = do.call(rbind, shapley_list_svm)

# 'average' shap for svm_predictor2
shapley_list_svm2 = list()
for (i in 1:21) {
  shapley_instance_svm2 = Shapley$new(svm_predictor2, x.interest = as.data.frame(outer_test_data[i, ]), sample.size = 5)
  shapley_values_svm2 = as.data.frame(shapley_instance_svm2$results)
  shapley_values_svm2$instance = i
  shapley_list_svm2[[i]] = shapley_values_svm2
}

shapley_all_svm2 = do.call(rbind, shapley_list_svm2)

#combined svm shaps
shap_combined <- rbind(shapley_all_svm, shapley_all_svm2)

shapley_combined_values_svm = shap_combined[order(-(shap_combined$phi)), ]
View(shapley_combined_values_svm)

top_5_shapley_svm = shapley_combined_values_svm[c(1,4,7,8,9),]

shapley_clin = shapley_combined_values_svm %>%
  filter(feature == "sex" | feature == "age" |
           feature == "mri" | feature == "nocturnal_sz" |
           feature == "risk_factors___1" |
           feature == "risk_factors___2" |
           feature == "risk_factors___3" |
           feature == "risk_factors___9"|
           feature == "sz_type" | feature == "eeg" | feature == "BrainPAD")
 
shap_clin_top3 <- shapley_clin[c(1,2,15),]

shapley_tib <- rbind(top_5_shapley_svm, shap_clin_top3)

shapley_tib$feature <- c("grey matter volume asymmetry",
              "LGI R temporal pole",
              "folding index L superior frontal gyrus",
              "LGI insula asymmetry",
              "L CA1 hippocampal subfield volume",
              "nocturnal first seizure",
              "non-epileptiform EEG abnorm",
              "generalised onset seizure")

shapley_tib$feature_type <- c("image","image","image","image","image",
                  "clin","clin","clin")

ggplot(shapley_tib, aes(x = reorder(feature, abs(phi)), y = phi, 
                           fill = feature_type)) +
  geom_bar(stat = "identity", width = 0.5) +
  coord_flip() +
  xlab(NULL) +
  ylab("Shapley Value") +
  ggtitle("Top Features SVM") +
  scale_fill_manual(values = c("darkorange", "darkblue")) +
  theme(axis.text.x = element_text(colour = "black", size = 22),
        axis.text.y = element_text(colour = "black", size = 22),
        axis.title.x = element_text(size = 22),
        axis.title.y = element_text(size = 22))

```
#save models
```{r save model}

saveRDS(results, file="results_190924.RData")
saveRDS(clin_pred, file = "clin_pred_190924.RData")
saveRDS(clin_model, file = "clin_model_190924.RData")

#to open
#results <- readRDS("~/results_190924.RData")


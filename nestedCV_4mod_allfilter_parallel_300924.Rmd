---
title: "nestedCV_filters_4 models"
description: "nested CV, with perm/PCA/AUC/no filter, in parallel"
author: "Suyi Ooi"
date: "2024-09-30"
output: html_document
---
iml#libraries
```{r libraries, include=FALSE}
#data
library(data.table)
library(dplyr)
library(ggpubr)
library(ggplot2)
library(patchwork)
library(igraph)

#ml/mlr3
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(mlr3filters)
library(mlr3fselect)
library(FSelectorRcpp)
library(mlr3pipelines)
library(mlr3benchmark)
library(mlr3data)
library(paradox)
library(mlr3viz)
library(precrec)
library(mlr3measures)
library(e1071)
library(xgboost)
library(ranger)
library(glmnet)
library(mlr3tuningspaces)
library(genalg)
library(factoextra)
library(FactoMineR)

#model intepretation
library(iml)
library(interp)
library(pROC)

#harmonisation
library(neuroCombat)

#parallelisation
library(future)
library(future.apply)

#functions and hyperparameters
setwd("~/Library/CloudStorage/OneDrive-TheUniversityofMelbourne/seizure_prediction/seizure_prediction")
source("functions.R")

```
#data
```{r data, include=FALSE}
#load t1 (clin and imaging), and brainPAD
t1 <- read.csv("~/Library/CloudStorage/OneDrive-TheUniversityofMelbourne/seizure_prediction/seizure_prediction/t1w.clin.image.scan.201.csv", header = TRUE)

brainage <- read.csv("~/Library/CloudStorage/OneDrive-TheUniversityofMelbourne/seizure_prediction/seizure_prediction/PyBrainAge_Output_suyi_20240709.csv", header = TRUE)

t1$X = NULL
t1$sex[t1$sex == "nonbinary"] <- "male"

brainage <- subset(brainage, select = c("BrainAge","BrainPAD"))

#combine imaging and brainage
t1.data = data.frame(t1,brainage)

#remove bendigo skyra and one subject
t1.dat = t1.data %>% filter(batch != "bendigo_skyra",
                            subject != "sub-eh0703")

#make categorical variables factor
t1.dat <- t1.dat %>% dplyr::mutate(across(where(is.character), factor))

#reference levels
t1.dat$szrec1 <- relevel(t1.dat$szrec1, ref = "no") #predicting YES
t1.dat$sz_type <- relevel(t1.dat$sz_type, ref = "unc") 
t1.dat$mri <- relevel(t1.dat$mri, ref = "normal")
t1.dat$eeg <- relevel(t1.dat$eeg, ref = "normal")
t1.dat$risk_factors___3 <- relevel(t1.dat$risk_factors___3, ref = "no")

#preprocess - prefix subcortical features for grep
start_hat <- which(names(t1.dat) == "r_lat_nucleus")
end_hat <- which(names(t1.dat) == "l_hippo_whole")
hat_range <- start_hat:end_hat
colnames(t1.dat)[start_hat:end_hat] <- paste0("subcort_", colnames(t1.dat[start_hat:end_hat]))

```
#filters
```{r filters}

filter_methods <- list(
  "pca" = po("pca") %>>% po("filter", filter = flt("variance"), filter.frac = 0.8),
  "perm" = po("filter", filter = flt("permutation"), param_vals = list(filter.frac = 0.3)),
  "auc_filter" = po("filter", filter = flt("auc"), param_vals = list(filter.frac = 0.5)),
  "no_filter" = po("nop"))

#factor preprocessing
factor_pipeline = po("scale", "center") %>>% po("removeconstants") %>>%
  po("collapsefactors", no_collapse_above_prevalence = 0.01) %>>%
  po("encode", method = "one-hot",
     affect_columns = selector_cardinality_greater_than(2),
     id = "low_card_enc") %>>%
  po("encode", method = "treatment",
     affect_columns = selector_type("factor"), id = "binary_enc") 

```
#task
```{r learner}
#define the task
task = TaskClassif$new(t1.dat, id = "szrec", target = "szrec1", positive = "yes")

#learners
learners <- list(lrn("classif.ranger",
                     id = "classif.ranger",
                     importance = "permutation",
                     predict_type = "prob"),
                 lrn("classif.xgboost",
                     id = "classif.xgboost",
                     predict_type = "prob"),
                 lrn("classif.glmnet",
                     id = "classif.glmnet",
                     predict_type = "prob"),
                 lrn("classif.svm",
                     id = "classif.svm",
                     type = "C-classification", kernel = "linear",
                     predict_type = "prob"))

# define measure
measure = msr("classif.auc")

#hyperparameter search strategy
tuner = mlr3tuning::tnr("random_search", batch_size = 1) #change depending on cores

#store results
train_sets <- list()
test_sets <- list()

results <- list()

clin_rr_train <- list()
clin_auc <- list()
clin_pred <- list()
clin_model <- list()

#rsmp strategy
outer_rsmp <- rsmp("custom")
inner_rsmp = rsmp("cv", folds = 10)
```
#nested CV
```{r outer, include=FALSE, r echo=FALSE, results='hide'}

#custom make 10 outer folds
set.seed(4)
k <- 10 
folds <- stratified_folds(task, k)

# outer fold

for (i in seq_len(k)) {
  
  test_set <- folds[[i]]
  train_set <- setdiff(task$row_ids, test_set)
  outer_rsmp$instantiate(task, list(train_set), list(test_set))
  
  train_sets[[i]] <- train_set #store these to check the shuffled indices
  test_sets[[i]] <- test_set
  
  #apply combat on the training set
  train_data <- t1.dat[train_set, ]
  test_data <- t1.dat[test_set, ]
  
  #extract feature lists
  train_df_list <- extract_featuregroup_list(train_data)
  test_df_list  <- extract_featuregroup_list(test_data)
  
  #biological covariates for combat
  covars.train = model.matrix(~age+factor(sex)+factor(szrec1), data=train_data)
  
  #batch
  batch.train = train_data$batch
  batch.test = test_data$batch 
  
  #apply combat function
  combat.train <- do_neuroCombat(train_df_list, batch.train, covars.train)
  
  #get dat.combat and estimates
  dat.combat.train.list <- lapply(combat.train, function(x) x$dat.combat)
  
  dat.combat.train <- get_dat_combated_df(dat.combat.train.list)
  
  #apply combat on test using the previously generated estimates
  cb.train.estimates <- lapply(combat.train, function(x) x$estimates)
  
  dat.combat.test.list <- do_neuroCombatFromTraining(
    test_df_list, batch.test, cb.train.estimates)
  
  dat.combat.test <- get_dat_combated_df(dat.combat.test.list)
  
  #extract clinical factor variables
  t1.clin <- extract_clin_factors(train_data)
  t1.clin.test <- extract_clin_factors(test_data)
  
  #combine combated df with clinical factors
  t1.train.new <- data.frame(t1.clin, dat.combat.train)
  t1.test.new <- data.frame(t1.clin.test, dat.combat.test)
  
  #outer train and test tasks
  outer_train_task = TaskClassif$new(t1.train.new, id = "train", target = "szrec1")
  outer_test_task = TaskClassif$new(t1.test.new, id = "test", target = "szrec1")
  
  #make inner train task from outer train set
  inner_train_task = outer_train_task$clone()
  
  graph_learners = list()
  
    for (learner in learners) {
    
    #make graph learners with the filters piped
      
        for (filter in names(filter_methods)) {
        
          graph_name <- paste(filter, learner$clone()$id, sep = ".")
        graph <- factor_pipeline %>>% filter_methods[[filter]] %>>%
          learner$clone()
        graph_learner <- GraphLearner$new(graph)
        graph_learner$id <- graph_name
        graph_learners <- c(graph_learners,
                          list(GraphLearner$new(graph_learner)))
        }
    } #end learners 
  
  #---inner loop: hyperparameter tuning for each graph learner---#
  
  results[[i]] <- list()
  
  for (j in seq_along(graph_learners)){
    
    #run inner loop in parallel
    
    future::plan(multisession, workers = 8) #uses workers are specified
      
    glrn <- graph_learners[[j]]
    
    results[[i]][[j]] <- future_lapply(list(glrn), function(glrn){
  
      #fallback
      glrn$encapsulate(method = "evaluate", fallback = lrn("classif.log_reg", predict_type = "prob"))
      
      #glrn$encapsulate <- c(train = "evaluate", predict = "evaluate")
      #glrn$fallback = lrn("classif.log_reg", predict_type = "prob")
    
      #hyperparameter set
      param_set <- create_param_sets(glrn$id)
    
      #tuning instance
      instance <- TuningInstanceSingleCrit$new(
      task = inner_train_task,
      learner = glrn,
      resampling = inner_rsmp,
      measure = measure,
      search_space = param_set,
      terminator = trm("evals", n_evals = 5) #increase for final run
    )
    
    tuner$optimize(instance)
    
    #instance$result_learner_param_vals
    #autoplot(instance)
    
    #assign tuned hyperparameters to learner
    glrn$param_set$values = instance$result_learner_param_vals
    
    #inner loop evaluation
    rr_inner <- resample(inner_train_task, glrn,
                         inner_rsmp,
                         store_models = FALSE)
    
    inner_auc <- rr_inner$aggregate(measure)
    
        #---Outer loop train/test evaluation---#
    
        glrn$train(outer_train_task)
        outer_prediction <- glrn$predict(outer_test_task)
        outer_auc <- outer_prediction$score(measure)
    
    #store results for each glrn
    list(
      learner = glrn$id,
      inner_performance = inner_auc,
      outer_performance = outer_auc,
      best_params = instance$result_learner_param_vals,
      outer_prediction = outer_prediction,
      model = glrn
    )
  }, future.seed = TRUE)
  
} #end graph_learners 

    #---clinical model---#
  
    #clin task train
    clin_task = outer_train_task$clone()
    clin_task$select(c("sex","age","mri",
                                 "nocturnal_sz",
                                 "risk_factors___2","risk_factors___3",
                                 "risk_factors___9","sz_type","eeg"))
    
    #clin task test
    clin_test_task = outer_test_task$clone()
    clin_test_task$select(c("sex","age","mri",
                                 "nocturnal_sz",
                                 "risk_factors___2","risk_factors___3",
                                 "risk_factors___9","sz_type","eeg"))

    #clin learner
    lrn_clin = lrn("classif.log_reg", predict_type = "prob")

    clin_glm = as_learner(factor_pipeline %>>% lrn_clin)

    instance_clin <- TuningInstanceSingleCrit$new(
      task = clin_task,
      learner = clin_glm,
      resampling = rsmp("cv", folds = 10),
      measure = measure,
      terminator = trm("evals", n_evals = 10) # change this
    )

    clin_rr <- resample(clin_task, clin_glm, rsmp("cv", folds = 10),
                        store_models = FALSE)
    clin_rr_train[[i]] <- clin_rr$aggregate(measure)

    #train on clin training task
    clin_glm$train(clin_task)
    
    #predict on test
    pred_clin = clin_glm$predict(clin_test_task)
    
    #clin auc
    clin_performance = pred_clin$score(msr("classif.auc"))
  
  #stores clinical model results
    
  clin_auc[[i]] <- clin_performance
  clin_pred[[i]] <- list(pred_clin)
  clin_model[[i]] <- clin_glm
  
} # end outer

```
#extract results
```{extract results}

#outer_auc
outer_auc <- extract_auc(results, "outer")
inner_auc <- extract_auc(results, "inner")

#top 4 models + clinical
models <- list(
  "no_filter.classif.ranger" = "pred_stack_rf",
  "no_filter.classif.xgboost" = "pred_stack_xgb",
  "pca.classif.glmnet" = "pred_stack_glm",
  "auc_filter.classif.svm" = "pred_stack_svm"
)

predictions <- stack_top4_predictions(results, models) 

```
#rocs
```{rocs}

colors <- c("darkblue", "darkred", "darkgreen", "darkorange", "dodgerblue")

labels <- c(
  paste0("1. Support Vector Machine (AUC = ", round(predictions$svm_stacked_roc$auc, digits = 2), ")"),
  paste0("2. Random Forest (AUC = ", round(predictions$rf_stacked_roc$auc, digits = 2), ")"),
  paste0("3. LASSO (AUC = ", round(predictions$glm_stacked_roc$auc, digits = 2), ")"),
  paste0("4. XGBoost (AUC = ", round(predictions$xgb_stacked_roc$auc, digits = 2), ")"),
  paste0("5. Clinical Model (AUC = ", round(predictions$clin_stacked_roc$auc, digits = 2), ")")
)

plot_rocs(predictions)

```
#model intepretation
```{r intepretation}
#needs to revise as all results are in 'results' list

#roc.test
#p<-roc.test(svm_stacked_roc, clin_stack_roc)
#p

#PCA loadings
#pca_glm_model3 = final_models[[3]][["pca.classif.glmnet"]]
#pca_glm_filter = pca_glm_model3$graph_model$pipeops[[1]]$state$model

# PC1:124
#glm_pca_loadings = as.data.frame(pca_glm_filter$pca$rotation[,1:126])

#shapley
#outer_test_data = as.data.table(outer_test_task$clone()$data())
outer_test_data = make_one_test_fold(t1.dat, 8)

#filtered features
#svm_features = results[[8]][[11]][[1]]$model$model$auc_filter.classif.svm$model$classif.svm$feature_names

#data_svm_features <- outer_test_data[, svm_features, drop = FALSE]


# predictor object
auc_filter_svm_model <- results[[8]][[11]][[1]]$model

svm_predictor = Predictor$new(
  model = auc_filter_svm_model,
  data = outer_test_data[,-1],  
  y = outer_test_data[,1],
  type = "prob",
  class = "yes"
)

# 'average' shap for svm_predictor
shapley_list_svm = list()
for (i in 1:20) {
  shapley_svm = Shapley$new(svm_predictor,
                            x.interest = outer_test_data[i, -1],
                            sample.size = 5)
  shapley_values_svm = as.data.frame(shapley_svm$results)
  shapley_values_svm$instance = i
  shapley_list_svm[[i]] = shapley_values_svm
}

shapley_all_svm = do.call(rbind, shapley_list_svm)

shapley_ordered = shapley_all_svm[order(-(shapley_all_svm$phi)), ]
View(shapley_ordered)

top_5_image_features <- unique(shapley_ordered$feature)[1:5]

#image table
shapley_top_5_image <- shapley_ordered[shapley_ordered$feature %in% top_5_image_features, ]

shapley_clin = shapley_all_svm %>%
  filter(feature == "sex" | feature == "age" |
           feature == "mri" | feature == "nocturnal_sz" |
           feature == "risk_factors___1" |
           feature == "risk_factors___2" |
           feature == "risk_factors___3" |
           feature == "risk_factors___9"|
           feature == "sz_type" | feature == "eeg" | feature == "BrainPAD")
 
top_5_clin_features <- unique(shapley_clin$feature)[1:5]

#clin table
shapley_top_5_clin <- shapley_ordered[shapley_ordered$feature %in% top_5_clin_features, ]

shapley_tib <- rbind(shapley_top_5_image, shapley_top_5_clin)

top_10_features <- unique(shapley_tib$feature)[1:10]
top_10_features

shapley_top_10_df <- shapley_tib[!duplicated(shapley_tib$feature), ]


#shapley_tib$feature <- c("grey matter volume asymmetry","LGI R temporal pole","folding index L superior frontal gyrus","LGI insula asymmetry","L CA1 hippocampal subfield volume","nocturnal first seizure","non-epileptiform EEG abnorm","generalised onset seizure")

shapley_top_10_df$feature_type <- as.character(c(rep("image", 5), rep("clin", 5)))

ggplot(shapley_top_10_df, aes(x = reorder(feature, abs(phi)), y = phi, 
                           fill = feature_type)) +
  geom_bar(stat = "identity", width = 0.5) +
  coord_flip() +
  xlab(NULL) +
  ylab("Shapley Value") +
  ggtitle("Top Features SVM") +
  scale_fill_manual(values = c("darkorange", "darkblue")) +
  theme(axis.text.x = element_text(colour = "black", size = 22),
        axis.text.y = element_text(colour = "black", size = 22),
        axis.title.x = element_text(size = 22),
        axis.title.y = element_text(size = 22))

```
#save models
```{r save model}

saveRDS(results, file="results_190924.RData")
saveRDS(clin_pred, file = "clin_pred_190924.RData")
saveRDS(clin_model, file = "clin_model_190924.RData")

#to open
#results <- readRDS("~/results_190924.RData")

